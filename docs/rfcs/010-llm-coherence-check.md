# RFC-010: Optional LLM-Based Coherence Check in Confidence Score

* **Status:** Proposed
* **Author:** Cline
* **Date:** 2025-03-30

## 1. Summary

This RFC proposes adding an *optional* mechanism to enhance the confidence score calculation by using an external Language Model (LLM) to directly assess the logical coherence and internal consistency of generated text (thoughts or drafts). This check replaces the current, less reliable heuristic-based coherence metrics when enabled.

## 2. Motivation

The current coherence assessment within the confidence calculation (e.g., `calculateCoherence`, `analyzeDraftCoherence`) relies on superficial metrics like sentence length and structure. These are poor proxies for actual logical flow and internal consistency. A generated text can easily pass these checks while being nonsensical or contradictory. To improve the reliability of the confidence score, particularly the component related to content quality, a more direct assessment of coherence is needed.

## 3. Proposed Change

1. **Optional Feature:** The LLM coherence check will be an optional feature, disabled by default.
2. **Enabling Mechanism:** The feature will be enabled if the user provides the necessary configuration via specific environment variables:
    * `COHERENCE_API_KEY`: API key for the LLM service.
    * `COHERENCE_CHECK_MODEL`: The specific model identifier to use for the check (e.g., `google/gemma-7b-it`, `gpt-3.5-turbo`).
    * `COHERENCE_API_BASE` (Optional): The base URL for the API endpoint (defaults to OpenAI if unset, allows pointing to OpenRouter, Azure, local servers like Ollama, etc.).
3. **API Interaction:**
    * Use the `openai` Node.js library to interact with the configured endpoint (supporting OpenAI-compatible APIs).
    * When the feature is enabled, within the confidence calculation process for each thought/draft, make an API call to the configured model.
4. **Prompting & Structured Output:**
    * Use a focused prompt instructing the LLM to evaluate *only* logical coherence and internal consistency on a 1-5 scale, ignoring grammar, style, and factual accuracy.
    * Utilize the `response_format` parameter with `type: "json_schema"` to request a structured JSON response: `{"rating": N}` where N is the numerical rating (1-5).
    * **Schema:**

        ```json
        {
          "name": "coherence_rating",
          "strict": true,
          "schema": {
            "type": "object",
            "properties": {
              "rating": {
                "type": "number",
                "description": "Coherence rating from 1 to 5.",
                "minimum": 1,
                "maximum": 5
              }
            },
            "required": ["rating"],
            "additionalProperties": false
          }
        }
        ```

5. **Response Handling & Fallback:**
    * Attempt to parse the LLM response as JSON and validate the presence and validity of the `rating` field (must be a number 1-5).
    * **Success:** If a valid rating is extracted, normalize it to a 0-1 scale (e.g., `(rating - 1) / 4`).
    * **Failure:** If the feature is disabled (env vars missing) OR the API call fails OR the response cannot be parsed OR the rating is invalid, log a warning and use a **neutral default score of 0.7** for the coherence component.
6. **Confidence Integration:**
    * The successfully obtained (and normalized) LLM rating OR the default fallback score (0.7) will replace the score previously generated by the heuristic coherence checks (`calculateCoherence`, `analyzeDraftCoherence`) within the weighted confidence calculation formulas in all relevant services (`SequentialThinkingService`, `ChainOfDraftService`, `IntegratedThinkingService`).
    * The old heuristic coherence functions will be removed.

## 4. Rationale

* **Improved Accuracy:** Directly assesses logical coherence using an LLM, providing a much stronger signal than simple heuristics.
* **Flexibility:** Allows users to choose their preferred LLM provider (OpenAI, OpenRouter, Azure, local) and model via standard environment variables.
* **Optionality:** Users not wanting the added latency, cost, or setup complexity can simply leave the environment variables unset, falling back to a neutral coherence score without breaking functionality.
* **Robustness:** Structured output (`response_format`) increases the reliability of parsing the LLM's rating. The fallback mechanism handles API errors or non-compliant responses gracefully.

## 5. Implementation Details

* **Dependency:** Add `npm install openai`.
* **Configuration:**
  * Add new optional environment variables: `COHERENCE_API_KEY`, `COHERENCE_CHECK_MODEL`, `COHERENCE_API_BASE`.
  * Add a boolean flag `enableLLMCoherenceCheck` to relevant config types (e.g., `CoreConfig`, `DraftConfig`, `IntegratedEnhancementConfig` - TBD which is most appropriate).
  * Update `ConfigurationManager` to check for the presence of `COHERENCE_API_KEY` and `COHERENCE_CHECK_MODEL` env vars and set the `enableLLMCoherenceCheck` flag accordingly during loading. Add default for `COHERENCE_CHECK_MODEL` (e.g., `"gpt-3.5-turbo"`).
* **New Utility (`src/utils/`):**
  * Create `CoherenceCheckerUtil` (or similar).
  * Handles instantiation of the `openai` client using the `COHERENCE_` env vars.
  * Provides an `async checkCoherence(text: string): Promise<number>` method that:
    * Checks the `enableLLMCoherenceCheck` config flag. Returns the default score (0.7) if false.
    * Formats the prompt.
    * Makes the API call using `chat.completions.create` with the prompt and `response_format`.
    * Parses and validates the JSON response.
    * Normalizes the valid rating (1-5 -> 0-1).
    * Returns the normalized score or the default score (0.7) on any failure (API error, parse error, invalid rating), logging appropriate warnings.
* **Refactoring:**
  * Modify `calculateConfidence` / `calculateDraftConfidence` / `calculateIntegratedConfidence` methods to be `async` (if not already).
  * Replace calls to old coherence functions with `await coherenceCheckerUtil.checkCoherence(text)`.
  * Adjust weighting within confidence formulas if necessary to account for the new coherence score range/meaning.
  * Remove old coherence functions (`calculateCoherence`, `analyzeDraftCoherence`).

## 6. Impact

* **Positive:** Potential for significantly more accurate confidence scores, better reflecting the logical quality of the generated text. User flexibility in choosing rating models.
* **Negative:**
  * Introduces external dependency (network call) or local LLM requirement when enabled.
  * Adds latency to each confidence calculation when enabled.
  * Potential cost associated with API calls when enabled.
  * Requires user setup (API key, potentially local server) to enable.
  * Adds complexity to the codebase.

## 7. Testing Plan

* Unit tests for `CoherenceCheckerUtil`, mocking the `openai` client and testing response parsing, normalization, and fallback logic.
* Integration tests for refactored `calculateConfidence` methods, ensuring they call the utility correctly and handle the returned score or fallback.
* End-to-end testing comparing confidence scores with the feature enabled vs. disabled, and ideally correlating LLM ratings with human judgments of coherence on benchmark texts. Test with different models (OpenAI, OpenRouter, local if possible).

## 8. Alternatives Considered

* **Heuristic Checks:** Current approach, deemed insufficient for measuring true coherence.
* **Semantic Embeddings for Coherence:** Using embeddings to measure similarity between adjacent sentences/paragraphs. Less direct than an LLM rating for logical flow and contradiction detection.
* **Non-Optional LLM Check:** Rejected due to performance, cost, and setup implications for users who may not need or want this level of checking.
